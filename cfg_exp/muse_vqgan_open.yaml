experiment:
    name: open_muse
    project_name: muse_vqgan
    max_train_examples: 2
    save_every: 1000
    eval_every: 100
    sample_every: 10010000000000
    log_every: 100
    log_level: info
    resume_path_from_checkpoint: null


codebook:
        codebook_dim: 32
        beta : 0.25
        codebook_size: 8192

vitvqgan:
    checkpoint : outputs/vitvqgan/checkpoints/VitVQGAN.pt
    transformer:
        dim : 512
        patch_size : 8
        n_heads : 8
        d_head : 64
        depth : 6
        dropout : 0.
        mlp_dim: 2048

model:
    name: open_muse
    dim : 768
    encoder:
        type: clip
        name : openai/clip-vit-large-patch14
        max_length : 77
    decoder:
        n_heads : 12
        d_head : 64
        depth : 16
        mult : 8
        dropout : 0.0

dataset:
    name: coco
    params:
        train_path:  /media/pranoy/UBUNTU_ROOT/home/pranoy/datasets/coco2017
        val_path: null
        num_workers: 4
        pin_memory: True
        batch_size: 2
        persistent_workers: True
        shuffle : True
        train_test_split : 0.9
    preprocessing:
        resolution: 256
        center_crop: False
        random_flip: False
        random_crop: True
        mean : null
        std : null
        scale : 1.0

optimizer:
    name: adamw
    params: 
        learning_rate: 1e-4
        beta1: 0.9
        beta2: 0.999
        weight_decay: 0.01

lr_scheduler:
    name: constant_with_warmup
    params:
        learning_rate: ${optimizer.params.learning_rate}
        warmup_steps: 1
        decay_steps: null

training:
    gradient_accumulation_steps: 1
    mixed_precision: "no"
    seed: 42
    num_epochs: 20000000
    max_grad_norm: null
